{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, LayerNormalization, Conv2D, Add, Dropout, Reshape, UpSampling2D, BatchNormalization, AveragePooling2D\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.saving import register_keras_serializable\n",
        "import random\n",
        "from google.colab import drive\n",
        "import cv2\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDWxM2rsDW1C",
        "outputId": "3b0818ad-4a03-4496-8f7e-9fca4c2f84b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot2label = {\n",
        "    0: \"Slow Motion\",\n",
        "    1: \"Wide Shot\",\n",
        "    2: \"Close-up\",\n",
        "    3: \"High Angle\",\n",
        "    4: \"Low Angle\",\n",
        "    5: \"Cinematic Lighting\",\n",
        "    6: \"Blurred Background\",\n",
        "    7: \"Fast Motion\",\n",
        "    8: \"Dynamic Movement\",\n",
        "    9: \"Hyper-realistic Detail\"}\n",
        "\n",
        "X, Y = [], []\n",
        "\n",
        "#Data Loading Here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FoDaZa4wTSJ",
        "outputId": "ab0cf2b8-0311-4b3b-861f-677aba8d46ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Folder: close-up\n",
            "(512, 512)\n",
            "(512, 512)\n",
            "\n",
            "Folder: medium-shot\n",
            "\n",
            "Folder: profile-shot\n",
            "\n",
            "Folder: titles\n",
            "\n",
            "Folder: wide-shot\n",
            "(512, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@register_keras_serializable()\n",
        "class embedify(tf.keras.layers.Layer):\n",
        "  def __init__(self, patch_size, emb_dim, **kwargs):\n",
        "    super(embedify, self).__init__(**kwargs)\n",
        "    self.emb_dim = emb_dim\n",
        "    self.patch_size = patch_size\n",
        "    self.conv_emb = Conv2D(filters=self.emb_dim, kernel_size=self.patch_size, strides=self.patch_size)\n",
        "    self.CLS_token = self.add_weight(\n",
        "        name=\"CLS_token\",\n",
        "        shape=(1, 1, self.emb_dim),\n",
        "        initializer=\"random_normal\",\n",
        "        trainable=True)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    num_patches = (input_shape[1] // self.patch_size) * (input_shape[2] // self.patch_size)\n",
        "    self.pos_emb = self.add_weight(\n",
        "        name=\"pos_emb\",\n",
        "        shape=(1, num_patches+1, self.emb_dim),\n",
        "        initializer=\"random_normal\",\n",
        "        trainable=True)\n",
        "    self.conv_emb.build(input_shape)\n",
        "    super().build(input_shape)\n",
        "\n",
        "  def call(self, x):\n",
        "    batch_size = tf.shape(x)[0]\n",
        "    x = self.conv_emb(x) #patchify into 16x16 patches\n",
        "    x = tf.reshape(x, (batch_size,  tf.shape(x)[1]* tf.shape(x)[2], self.emb_dim)) #flatten into patch array\n",
        "    CLS = tf.tile(self.CLS_token, [batch_size, 1, 1]) #add CLS token\n",
        "    x = tf.concat([CLS, x], axis=1)\n",
        "    x += self.pos_emb #add learnable pos enc (no sinusoid)\n",
        "    return x\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({\"patch_size\": self.patch_size, \"emb_dim\": self.emb_dim})\n",
        "    return config\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    h, w = input_shape[1], input_shape[2]\n",
        "    num_patches = (h // self.patch_size) * (w // self.patch_size)\n",
        "    return (input_shape[0], num_patches, self.emb_dim)\n",
        "\n",
        "@register_keras_serializable()\n",
        "class attentify(tf.keras.layers.Layer):\n",
        "  def __init__(self, emb_dim, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.emb_dim = emb_dim\n",
        "    self.Q = self.add_weight(shape=(emb_dim, emb_dim), initializer='glorot_uniform', name='Q', trainable=True)\n",
        "    self.K = self.add_weight(shape=(emb_dim, emb_dim), initializer='glorot_uniform', name='K', trainable=True)\n",
        "\n",
        "  def call(self, x):\n",
        "    Qx = tf.matmul(x, self.Q)\n",
        "    Kx = tf.matmul(x, self.K)\n",
        "    A = tf.matmul(Qx, Kx, transpose_b=True) / tf.math.sqrt(tf.cast(self.emb_dim, tf.float32))\n",
        "    A = tf.nn.softmax(A)\n",
        "    x = tf.matmul(A, x) + x\n",
        "    return x\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({\"emb_dim\": self.emb_dim})\n",
        "    return config\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return input_shape\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    super().build(input_shape)\n",
        "\n",
        "@register_keras_serializable()\n",
        "class MLPify(tf.keras.layers.Layer):\n",
        "  # __NOTES__\n",
        "  def __init__(self, emb_dim, expansion_multiplier, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.emb_dim = emb_dim\n",
        "    self.expansion_multiplier = expansion_multiplier\n",
        "    self.denseUp = Dense(self.emb_dim*self.expansion_multiplier, activation=\"gelu\")\n",
        "    self.denseDown = Dense(self.emb_dim, activation=\"gelu\")\n",
        "    self.dropout = Dropout(0.1)\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    dx = self.denseUp(x)\n",
        "    dx = self.denseDown(dx)\n",
        "    dx = self.dropout(dx,training=training)\n",
        "    x = x + dx\n",
        "    return x\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.denseUp.build(input_shape)  # input: (batch, context, emb_dim)\n",
        "    up_out_shape = self.denseUp.compute_output_shape(input_shape)\n",
        "    self.denseDown.build(up_out_shape)\n",
        "    self.dropout.build(up_out_shape)\n",
        "    super().build(input_shape)\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return input_shape\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({\"emb_dim\": self.emb_dim, \"expansion_multiplier\": self.expansion_multiplier})\n",
        "    return config\n",
        "\n",
        "@register_keras_serializable()\n",
        "class transformify(tf.keras.layers.Layer):\n",
        "  def __init__(self, emb_dim, head_no, dropout, **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.attentifys = [attentify(emb_dim) for _ in range(head_no)]\n",
        "    self.emb_dim = emb_dim\n",
        "    self.mlp = MLPify(emb_dim, 4)\n",
        "    self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "    self.dense_projection = Dense(emb_dim)\n",
        "    self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "    self.dropout1 = Dropout(dropout)\n",
        "    self.dropout2 = Dropout(dropout)\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    input_shape = x.shape\n",
        "    x = self.layernorm1(x)\n",
        "    attn = [att(x) for att in self.attentifys]\n",
        "    x = tf.concat(attn, axis=-1)\n",
        "    x = self.dense_projection(x)\n",
        "    x = self.dropout1(x, training=training)\n",
        "    x = self.layernorm2(x)\n",
        "    x = self.mlp(x, training=training)\n",
        "    x = self.dropout2(x, training=training)\n",
        "    return x\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({\"emb_dim\": self.emb_dim, \"head_no\": len(self.attentifys), \"dropout\": self.dropout1.rate})\n",
        "    return config\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return input_shape\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    for attn in self.attentifys:\n",
        "      attn.build(input_shape)\n",
        "    self.layernorm1.build(input_shape)\n",
        "    self.layernorm2.build(input_shape)\n",
        "    self.mlp.build(input_shape)\n",
        "    self.dropout1.build(input_shape)\n",
        "    self.dropout2.build(input_shape)\n",
        "    self.dense_projection.build((input_shape[0], input_shape[1], len(self.attentifys) * self.emb_dim))  # (batch_size, num_tokens, head_no * emb_dim)\n",
        "    super().build(input_shape)"
      ],
      "metadata": {
        "id": "yFZr2CAgzpaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(patch_size=16, emb_dim=300, head_no=4, dropout=0.1, transformer_layers=6,):\n",
        "  inputs = Input(shape=(512, 512, 3))\n",
        "\n",
        "  #__ViT__\n",
        "  x = embedify(16, 300)(inputs)\n",
        "  for _ in range(transformer_layers):\n",
        "    x = transformify(emb_dim, head_no, dropout)(x, training=False)\n",
        "  x = MLPify(300, 4)(x)\n",
        "  CLS = x[:,0,:]\n",
        "  CLS = Dense(10, activation='softmax')(CLS)\n",
        "  return tf.keras.Model(inputs, CLS, name=\"Lightweight-ViT-Encoder-Classification\")"
      ],
      "metadata": {
        "id": "vvlJhkfUz4DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViTDataGen(tf.keras.utils.Sequence):\n",
        "  def __init__(self, X, Y, batch_size=16, shuffle=True):\n",
        "    super().__init__()  # THIS IS IMPORTANT\n",
        "    self.X = X\n",
        "    #print(X[0].shape)\n",
        "    self.Y = Y\n",
        "    self.batch_size = batch_size\n",
        "    self.shuffle = shuffle\n",
        "\n",
        "    self.indices = np.arange(len(X))\n",
        "    if self.shuffle:\n",
        "        np.random.shuffle(self.indices)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.indices) // self.batch_size\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    #np.expand_dims(np.array(X[0]), axis=0)\n",
        "    indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "    X = np.stack([self.X[i] for i in indices])\n",
        "    Y = np.stack([self.Y[i] for i in indices])\n",
        "    return (X, Y)  # Return a tuple, not a list\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "    if self.shuffle:\n",
        "        np.random.shuffle(self.indices)"
      ],
      "metadata": {
        "id": "5sjdAuVGRrWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ViT = create_model()\n",
        "ViT.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoCL50KW2Dy7",
        "outputId": "80e7ad69-c7c1-429d-b45f-f112164f68dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Lightweight-ViT-Encoder-Classification\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Lightweight-ViT-Encoder-Classification\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedify (\u001b[38;5;33membedify\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m300\u001b[0m)      │       \u001b[38;5;34m538,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify (\u001b[38;5;33mtransformify\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m300\u001b[0m)      │     \u001b[38;5;34m1,803,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify_1 (\u001b[38;5;33mtransformify\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m300\u001b[0m)      │     \u001b[38;5;34m1,803,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify_2 (\u001b[38;5;33mtransformify\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m300\u001b[0m)      │     \u001b[38;5;34m1,803,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify_3 (\u001b[38;5;33mtransformify\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m300\u001b[0m)      │     \u001b[38;5;34m1,803,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify_4 (\u001b[38;5;33mtransformify\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m300\u001b[0m)      │     \u001b[38;5;34m1,803,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify_5 (\u001b[38;5;33mtransformify\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m300\u001b[0m)      │     \u001b[38;5;34m1,803,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ ml_pify_6 (\u001b[38;5;33mMLPify\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m300\u001b[0m)      │       \u001b[38;5;34m721,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ get_item (\u001b[38;5;33mGetItem\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m3,010\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedify (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">embedify</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">538,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">transformify</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,803,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">transformify</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,803,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">transformify</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,803,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">transformify</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,803,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">transformify</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,803,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ transformify_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">transformify</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,803,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ ml_pify_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MLPify</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">721,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ get_item (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GetItem</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,010</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,081,010\u001b[0m (46.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,081,010</span> (46.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,081,010\u001b[0m (46.09 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,081,010</span> (46.09 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ViT.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2W_Q6QQvK6Io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.expand_dims(np.array(X[0]), axis=0)\n",
        "print(x.shape)\n",
        "ViT.predict(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RxGAZSELV2j",
        "outputId": "e2468914-b16b-4e4e-b569-6a72a6bec526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 512, 512, 3)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00353501, 0.01144199, 0.05601081, 0.40686488, 0.4272279 ,\n",
              "        0.00886884, 0.01637472, 0.04429984, 0.00210371, 0.02327227]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ViT.fit(ViTDataGen(X,Y), epochs=3, batch_size=16)"
      ],
      "metadata": {
        "id": "z4Gp13AORLsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ViT.save('ViT_Weights.keras')"
      ],
      "metadata": {
        "id": "EiaHylWIlGBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vit = tf.keras.models.load_model('ViT_Weights.keras')"
      ],
      "metadata": {
        "id": "gAoFhWZllgKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf = vit.predict(np.expand_dims(np.array(X[random.randint(0,5000)]), axis=0))\n",
        "print(pdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LAshRZ68iNQ",
        "outputId": "0ac16e92-2b8e-42a4-c0a9-39f1020e01f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "[[0.00379678 0.00297844 0.26176834 0.12760867 0.08178452 0.25893638\n",
            "  0.0057682  0.00677026 0.14552607 0.10506228]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onehot2label[np.argmax(pdf)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zrdvLKx88yZx",
        "outputId": "cbd50655-8dbf-4267-fca8-df36be35529c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Close-up'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}